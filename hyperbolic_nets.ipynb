{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoopt as g\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from hierarchy_transformers import HierarchyTransformer\n",
    "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments, EvalPrediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic text similarity\n",
    "sts_b = load_dataset(\"glue\", \"stsb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer for the model\n",
    "tokenizer_HiT = AutoTokenizer.from_pretrained(\"Hierarchy-Transformers/HiT-MiniLM-L12-WordNetNoun\")\n",
    "tokenizer_allMini = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5dff87606694e6d88ddd61c109d8550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de01be8c3b44b0496ab1833da6bad0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the datasets\n",
    "\n",
    "def process_samples(samples, tokenizer):\n",
    "    # Tokenize the text via the tokenizer\n",
    "    return tokenizer(samples[\"sentence1\"], samples[\"sentence2\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "sts_b_HT = sts_b.map(lambda x: process_samples(x, tokenizer_HiT), batched=True)\n",
    "sts_b_LM = sts_b.map(lambda x: process_samples(x, tokenizer_allMini), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "\n",
    "def format_to_torch(dataset, label_key): \n",
    "    dataset = dataset.remove_columns([\"idx\"])\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', label_key])\n",
    "    return dataset\n",
    "\n",
    "def normalize_labels(example):\n",
    "\texample['label'] = example['label'] / 5.0\n",
    "\treturn example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9a30813f7b47ac8e06be432f9d97e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db7e1f316f84a26859cd6d36b33fe86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sts_b_LM_formatted = format_to_torch(sts_b_LM['validation'], \"label\").map(normalize_labels)\n",
    "sts_b_HT_formatted = format_to_torch(sts_b_HT['validation'], \"label\").map(normalize_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "\n",
    "hit = HierarchyTransformer.from_pretrained(\"Hierarchy-Transformers/HiT-MiniLM-L12-WordNetNoun\")\n",
    "elm = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierarchyTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elm.to('mps')\n",
    "hit.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(evaluation_prediction):\n",
    "    logits, labels = evaluation_prediction\n",
    "    predictions = np.argmax(logits, axis=1) # classification\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "def evaluate_model(model, dataset, batch_size=16):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    model.eval()\n",
    "    device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            all_logits.append(logits)\n",
    "            all_labels.append(batch[\"labels\"]).cpu()\n",
    "    \n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperbolic Model Performance:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "SentenceTransformer.forward() missing 1 required positional argument: 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate Hyperbolic Model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperbolic Model Performance:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTS-B:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msts_b_HT_formatted\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Evaluate Euclidean Model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEuclidean Model Performance:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 20\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, dataset, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     19\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     23\u001b[0m     all_logits\u001b[38;5;241m.\u001b[39mappend(logits)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/hitmodels/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/hitmodels/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: SentenceTransformer.forward() missing 1 required positional argument: 'input'"
     ]
    }
   ],
   "source": [
    "# Evaluate Hyperbolic Model\n",
    "print(\"Hyperbolic Model Performance:\")\n",
    "print(\"STS-B:\", evaluate_model(hit, sts_b_HT_formatted))\n",
    "\n",
    "# Evaluate Euclidean Model\n",
    "print(\"\\nEuclidean Model Performance:\")\n",
    "print(\"STS-B:\", evaluate_model(elm, sts_b_LM_formatted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def evaluate_model(model, dataset, batch_size=16, is_regression=False):\n",
    "    \"\"\"\n",
    "    Evaluate a SentenceTransformer model on a dataset.\n",
    "    - `is_regression`: Set to True for STS-B where labels are continuous scores.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            sentences1 = batch[\"sentence1\"]\n",
    "            sentences2 = batch[\"sentence2\"]\n",
    "            labels = batch[\"labels\"].numpy()  # Extract labels\n",
    "\n",
    "            # Compute sentence embeddings\n",
    "            embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "            embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "            # Compute cosine similarity\n",
    "            similarity_scores = torch.nn.functional.cosine_similarity(embeddings1, embeddings2).cpu().numpy()\n",
    "\n",
    "            all_predictions.extend(similarity_scores)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Compute evaluation metric\n",
    "    if is_regression:  # STS-B task (regression)\n",
    "        from scipy.stats import pearsonr\n",
    "        metric = {\"pearson_correlation\": pearsonr(all_predictions, all_labels)[0]}\n",
    "    else:  # Classification task (SNLI, QQP)\n",
    "        predictions = (all_predictions > 0.5).astype(int)  # Binary classification threshold\n",
    "        accuracy = np.mean(predictions == all_labels)\n",
    "        metric = {\"accuracy\": accuracy}\n",
    "\n",
    "    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.0,\n",
       " 4.75,\n",
       " 5.0,\n",
       " 2.4000000953674316,\n",
       " 2.75,\n",
       " 2.615000009536743,\n",
       " 5.0,\n",
       " 2.3329999446868896,\n",
       " 3.75,\n",
       " 5.0,\n",
       " 3.200000047683716,\n",
       " 1.5829999446868896,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 4.908999919891357,\n",
       " 0.800000011920929,\n",
       " 2.4000000953674316,\n",
       " 5.0,\n",
       " 4.0,\n",
       " 0.6359999775886536,\n",
       " 3.0,\n",
       " 1.7139999866485596,\n",
       " 3.200000047683716,\n",
       " 2.1670000553131104,\n",
       " 1.0,\n",
       " 1.9170000553131104,\n",
       " 4.25,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 0.6000000238418579,\n",
       " 2.5999999046325684,\n",
       " 5.0,\n",
       " 4.599999904632568,\n",
       " 5.0,\n",
       " 4.800000190734863,\n",
       " 3.799999952316284,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 4.199999809265137,\n",
       " 1.399999976158142,\n",
       " 3.5999999046325684,\n",
       " 2.799999952316284,\n",
       " 1.600000023841858,\n",
       " 3.0,\n",
       " 1.399999976158142,\n",
       " 0.25,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.5,\n",
       " 0.5,\n",
       " 3.799999952316284,\n",
       " 4.800000190734863,\n",
       " 5.0,\n",
       " 0.25,\n",
       " 1.2000000476837158,\n",
       " 0.6000000238418579,\n",
       " 0.800000011920929,\n",
       " 3.799999952316284,\n",
       " 0.0,\n",
       " 3.5,\n",
       " 4.5,\n",
       " 2.799999952316284,\n",
       " 3.799999952316284,\n",
       " 3.799999952316284,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.25,\n",
       " 2.812000036239624,\n",
       " 4.25,\n",
       " 3.0,\n",
       " 1.0,\n",
       " 3.75,\n",
       " 0.0,\n",
       " 0.4000000059604645,\n",
       " 4.0,\n",
       " 2.799999952316284,\n",
       " 3.75,\n",
       " 1.1540000438690186,\n",
       " 2.75,\n",
       " 2.799999952316284,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.4000000953674316,\n",
       " 5.0,\n",
       " 0.800000011920929,\n",
       " 2.25,\n",
       " 2.75,\n",
       " 4.5,\n",
       " 2.5999999046325684,\n",
       " 3.799999952316284,\n",
       " 2.799999952316284,\n",
       " 1.600000023841858,\n",
       " 0.0,\n",
       " 1.3329999446868896,\n",
       " 2.5999999046325684,\n",
       " 0.6000000238418579,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 0.20000000298023224,\n",
       " 3.200000047683716,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 3.0910000801086426,\n",
       " 2.75,\n",
       " 1.2000000476837158,\n",
       " 0.5,\n",
       " 0.25,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.6000000238418579,\n",
       " 4.0,\n",
       " 3.4000000953674316,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 2.4000000953674316,\n",
       " 0.4000000059604645,\n",
       " 1.7999999523162842,\n",
       " 2.5,\n",
       " 0.08299999684095383,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 4.5,\n",
       " 0.0,\n",
       " 3.5999999046325684,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 3.799999952316284,\n",
       " 5.0,\n",
       " 2.5,\n",
       " 3.8239998817443848,\n",
       " 1.600000023841858,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 2.375,\n",
       " 5.0,\n",
       " 1.25,\n",
       " 1.25,\n",
       " 3.0,\n",
       " 2.1670000553131104,\n",
       " 1.399999976158142,\n",
       " 4.0,\n",
       " 3.5999999046325684,\n",
       " 4.85699987411499,\n",
       " 0.4000000059604645,\n",
       " 0.20000000298023224,\n",
       " 1.2999999523162842,\n",
       " 1.2000000476837158,\n",
       " 1.2000000476837158,\n",
       " 4.400000095367432,\n",
       " 1.7999999523162842,\n",
       " 1.399999976158142,\n",
       " 0.4000000059604645,\n",
       " 4.400000095367432,\n",
       " 3.25,\n",
       " 0.777999997138977,\n",
       " 2.25,\n",
       " 2.75,\n",
       " 2.0,\n",
       " 0.8330000042915344,\n",
       " 3.75,\n",
       " 1.7999999523162842,\n",
       " 4.333000183105469,\n",
       " 4.214000225067139,\n",
       " 0.0,\n",
       " 3.4000000953674316,\n",
       " 4.199999809265137,\n",
       " 0.800000011920929,\n",
       " 4.199999809265137,\n",
       " 2.75,\n",
       " 2.200000047683716,\n",
       " 1.2000000476837158,\n",
       " 1.0,\n",
       " 1.5329999923706055,\n",
       " 0.20000000298023224,\n",
       " 3.0,\n",
       " 3.799999952316284,\n",
       " 0.75,\n",
       " 3.0,\n",
       " 0.4000000059604645,\n",
       " 3.4000000953674316,\n",
       " 3.799999952316284,\n",
       " 1.399999976158142,\n",
       " 3.4000000953674316,\n",
       " 3.200000047683716,\n",
       " 2.3329999446868896,\n",
       " 0.800000011920929,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 3.75,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.4000000059604645,\n",
       " 0.75,\n",
       " 2.5,\n",
       " 1.7999999523162842,\n",
       " 2.5,\n",
       " 0.5,\n",
       " 0.4000000059604645,\n",
       " 1.2000000476837158,\n",
       " 2.75,\n",
       " 0.4000000059604645,\n",
       " 0.6000000238418579,\n",
       " 0.800000011920929,\n",
       " 3.0,\n",
       " 0.4000000059604645,\n",
       " 3.200000047683716,\n",
       " 1.25,\n",
       " 5.0,\n",
       " 0.20000000298023224,\n",
       " 3.0,\n",
       " 1.399999976158142,\n",
       " 3.799999952316284,\n",
       " 2.75,\n",
       " 0.0,\n",
       " 2.799999952316284,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.5999999046325684,\n",
       " 0.10000000149011612,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 3.75,\n",
       " 3.0999999046325684,\n",
       " 2.691999912261963,\n",
       " 4.428999900817871,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 0.800000011920929,\n",
       " 1.3329999446868896,\n",
       " 0.0,\n",
       " 0.6000000238418579,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.4000000953674316,\n",
       " 2.200000047683716,\n",
       " 0.0,\n",
       " 3.5999999046325684,\n",
       " 0.0,\n",
       " 1.399999976158142,\n",
       " 2.200000047683716,\n",
       " 3.799999952316284,\n",
       " 2.5999999046325684,\n",
       " 0.4000000059604645,\n",
       " 4.0,\n",
       " 2.25,\n",
       " 3.200000047683716,\n",
       " 0.0,\n",
       " 0.4000000059604645,\n",
       " 3.799999952316284,\n",
       " 0.800000011920929,\n",
       " 4.199999809265137,\n",
       " 3.5999999046325684,\n",
       " 2.0,\n",
       " 4.199999809265137,\n",
       " 3.4000000953674316,\n",
       " 3.0,\n",
       " 3.4000000953674316,\n",
       " 3.5999999046325684,\n",
       " 3.0,\n",
       " 2.4000000953674316,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 4.199999809265137,\n",
       " 0.800000011920929,\n",
       " 2.200000047683716,\n",
       " 3.799999952316284,\n",
       " 3.200000047683716,\n",
       " 4.400000095367432,\n",
       " 0.0,\n",
       " 1.399999976158142,\n",
       " 2.5999999046325684,\n",
       " 0.4000000059604645,\n",
       " 0.0,\n",
       " 3.200000047683716,\n",
       " 4.599999904632568,\n",
       " 0.0,\n",
       " 0.6000000238418579,\n",
       " 1.2000000476837158,\n",
       " 3.799999952316284,\n",
       " 3.200000047683716,\n",
       " 2.5999999046325684,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 3.200000047683716,\n",
       " 4.0,\n",
       " 1.2000000476837158,\n",
       " 4.400000095367432,\n",
       " 3.4000000953674316,\n",
       " 4.400000095367432,\n",
       " 0.800000011920929,\n",
       " 4.599999904632568,\n",
       " 4.199999809265137,\n",
       " 0.0,\n",
       " 3.200000047683716,\n",
       " 0.0,\n",
       " 1.399999976158142,\n",
       " 3.200000047683716,\n",
       " 1.7999999523162842,\n",
       " 1.7999999523162842,\n",
       " 0.0,\n",
       " 3.799999952316284,\n",
       " 3.799999952316284,\n",
       " 4.0,\n",
       " 0.0,\n",
       " 3.200000047683716,\n",
       " 1.600000023841858,\n",
       " 3.5999999046325684,\n",
       " 1.0,\n",
       " 3.5999999046325684,\n",
       " 2.0,\n",
       " 3.5999999046325684,\n",
       " 4.0,\n",
       " 3.5999999046325684,\n",
       " 3.200000047683716,\n",
       " 2.799999952316284,\n",
       " 2.4000000953674316,\n",
       " 3.5999999046325684,\n",
       " 1.7999999523162842,\n",
       " 0.20000000298023224,\n",
       " 3.4000000953674316,\n",
       " 1.2000000476837158,\n",
       " 1.399999976158142,\n",
       " 2.5999999046325684,\n",
       " 2.4000000953674316,\n",
       " 0.0,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 4.0,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 2.200000047683716,\n",
       " 2.200000047683716,\n",
       " 3.4000000953674316,\n",
       " 3.200000047683716,\n",
       " 4.0,\n",
       " 3.200000047683716,\n",
       " 3.799999952316284,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 2.200000047683716,\n",
       " 3.4000000953674316,\n",
       " 3.799999952316284,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 4.800000190734863,\n",
       " 3.0,\n",
       " 0.800000011920929,\n",
       " 4.199999809265137,\n",
       " 4.199999809265137,\n",
       " 0.0,\n",
       " 4.199999809265137,\n",
       " 4.599999904632568,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 3.200000047683716,\n",
       " 2.5999999046325684,\n",
       " 2.200000047683716,\n",
       " 4.599999904632568,\n",
       " 5.0,\n",
       " 4.599999904632568,\n",
       " 4.599999904632568,\n",
       " 4.800000190734863,\n",
       " 0.6000000238418579,\n",
       " 0.20000000298023224,\n",
       " 2.200000047683716,\n",
       " 4.800000190734863,\n",
       " 1.2000000476837158,\n",
       " 2.200000047683716,\n",
       " 4.599999904632568,\n",
       " 2.5999999046325684,\n",
       " 3.5999999046325684,\n",
       " 0.800000011920929,\n",
       " 2.4000000953674316,\n",
       " 4.800000190734863,\n",
       " 5.0,\n",
       " 0.4000000059604645,\n",
       " 3.200000047683716,\n",
       " 1.7999999523162842,\n",
       " 3.200000047683716,\n",
       " 3.4000000953674316,\n",
       " 4.800000190734863,\n",
       " 4.199999809265137,\n",
       " 2.5999999046325684,\n",
       " 2.200000047683716,\n",
       " 1.399999976158142,\n",
       " 2.5999999046325684,\n",
       " 1.2000000476837158,\n",
       " 1.7999999523162842,\n",
       " 4.0,\n",
       " 0.4000000059604645,\n",
       " 0.0,\n",
       " 0.4000000059604645,\n",
       " 3.0,\n",
       " 4.0,\n",
       " 1.399999976158142,\n",
       " 0.4000000059604645,\n",
       " 2.4000000953674316,\n",
       " 2.799999952316284,\n",
       " 4.599999904632568,\n",
       " 4.199999809265137,\n",
       " 3.200000047683716,\n",
       " 1.2000000476837158,\n",
       " 1.7999999523162842,\n",
       " 2.5999999046325684,\n",
       " 1.600000023841858,\n",
       " 0.0,\n",
       " 3.799999952316284,\n",
       " 4.0,\n",
       " 4.800000190734863,\n",
       " 2.4000000953674316,\n",
       " 5.0,\n",
       " 0.0,\n",
       " 3.5999999046325684,\n",
       " 2.4000000953674316,\n",
       " 4.199999809265137,\n",
       " 0.20000000298023224,\n",
       " 4.199999809265137,\n",
       " 3.200000047683716,\n",
       " 0.6000000238418579,\n",
       " 1.600000023841858,\n",
       " 0.0,\n",
       " 1.399999976158142,\n",
       " 4.800000190734863,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.20000000298023224,\n",
       " 1.600000023841858,\n",
       " 4.400000095367432,\n",
       " 4.800000190734863,\n",
       " 0.4000000059604645,\n",
       " 2.4000000953674316,\n",
       " 3.0,\n",
       " 2.0,\n",
       " 4.599999904632568,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 1.399999976158142,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.6000000238418579,\n",
       " 0.0,\n",
       " 2.5999999046325684,\n",
       " 1.2000000476837158,\n",
       " 5.0,\n",
       " 3.4000000953674316,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 2.4000000953674316,\n",
       " 2.200000047683716,\n",
       " 3.799999952316284,\n",
       " 2.200000047683716,\n",
       " 4.599999904632568,\n",
       " 2.799999952316284,\n",
       " 2.0,\n",
       " 4.199999809265137,\n",
       " 4.5,\n",
       " 0.0,\n",
       " 1.7999999523162842,\n",
       " 4.199999809265137,\n",
       " 4.199999809265137,\n",
       " 1.399999976158142,\n",
       " 3.5999999046325684,\n",
       " 0.6000000238418579,\n",
       " 5.0,\n",
       " 0.800000011920929,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.7999999523162842,\n",
       " 0.800000011920929,\n",
       " 2.799999952316284,\n",
       " 0.0,\n",
       " 0.800000011920929,\n",
       " 1.7999999523162842,\n",
       " 1.399999976158142,\n",
       " 1.7999999523162842,\n",
       " 2.4000000953674316,\n",
       " 1.600000023841858,\n",
       " 3.799999952316284,\n",
       " 4.800000190734863,\n",
       " 0.20000000298023224,\n",
       " 1.0,\n",
       " 0.4000000059604645,\n",
       " 0.4000000059604645,\n",
       " 4.0,\n",
       " 3.4000000953674316,\n",
       " 3.0,\n",
       " 1.7999999523162842,\n",
       " 2.200000047683716,\n",
       " 3.5999999046325684,\n",
       " 0.4000000059604645,\n",
       " 0.20000000298023224,\n",
       " 3.799999952316284,\n",
       " 4.199999809265137,\n",
       " 1.2000000476837158,\n",
       " 3.4000000953674316,\n",
       " 2.4000000953674316,\n",
       " 3.200000047683716,\n",
       " 2.200000047683716,\n",
       " 4.400000095367432,\n",
       " 2.5999999046325684,\n",
       " 0.20000000298023224,\n",
       " 3.200000047683716,\n",
       " 2.200000047683716,\n",
       " 5.0,\n",
       " 5.0,\n",
       " 2.200000047683716,\n",
       " 0.4000000059604645,\n",
       " 1.0,\n",
       " 2.200000047683716,\n",
       " 2.0,\n",
       " 1.2000000476837158,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 4.199999809265137,\n",
       " 3.4000000953674316,\n",
       " 4.0,\n",
       " 4.800000190734863,\n",
       " 0.4000000059604645,\n",
       " 4.400000095367432,\n",
       " 0.4000000059604645,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 4.599999904632568,\n",
       " 0.4000000059604645,\n",
       " 1.399999976158142,\n",
       " 3.0,\n",
       " 1.600000023841858,\n",
       " 2.4000000953674316,\n",
       " 0.0,\n",
       " 1.600000023841858,\n",
       " 1.600000023841858,\n",
       " 0.20000000298023224,\n",
       " 2.200000047683716,\n",
       " 2.0,\n",
       " 0.4000000059604645,\n",
       " 4.800000190734863,\n",
       " 2.0,\n",
       " 0.20000000298023224,\n",
       " 3.799999952316284,\n",
       " 2.200000047683716,\n",
       " 2.0,\n",
       " 4.0,\n",
       " 4.599999904632568,\n",
       " 1.399999976158142,\n",
       " 0.800000011920929,\n",
       " 0.6000000238418579,\n",
       " 1.2000000476837158,\n",
       " 1.600000023841858,\n",
       " 0.0,\n",
       " 0.6000000238418579,\n",
       " 3.0,\n",
       " 2.4000000953674316,\n",
       " 0.6000000238418579,\n",
       " 4.599999904632568,\n",
       " 0.6000000238418579,\n",
       " 4.800000190734863,\n",
       " 5.0,\n",
       " 0.20000000298023224,\n",
       " 0.6000000238418579,\n",
       " 0.800000011920929,\n",
       " 3.5999999046325684,\n",
       " 0.0,\n",
       " 4.400000095367432,\n",
       " 4.599999904632568,\n",
       " 2.799999952316284,\n",
       " 4.0,\n",
       " 1.0,\n",
       " 5.0,\n",
       " 0.4000000059604645,\n",
       " 0.800000011920929,\n",
       " 0.4000000059604645,\n",
       " 0.0,\n",
       " 1.600000023841858,\n",
       " 1.600000023841858,\n",
       " 3.5999999046325684,\n",
       " 3.0,\n",
       " 2.799999952316284,\n",
       " 0.20000000298023224,\n",
       " 1.0,\n",
       " 1.399999976158142,\n",
       " 2.799999952316284,\n",
       " 3.0,\n",
       " 1.600000023841858,\n",
       " 2.799999952316284,\n",
       " 4.0,\n",
       " 0.800000011920929,\n",
       " 2.0,\n",
       " 4.400000095367432,\n",
       " 4.599999904632568,\n",
       " 2.4000000953674316,\n",
       " 4.400000095367432,\n",
       " 0.800000011920929,\n",
       " 3.799999952316284,\n",
       " 1.399999976158142,\n",
       " 2.799999952316284,\n",
       " 3.0,\n",
       " 1.600000023841858,\n",
       " 1.0,\n",
       " 2.5999999046325684,\n",
       " 1.600000023841858,\n",
       " 0.20000000298023224,\n",
       " 3.0,\n",
       " 3.0,\n",
       " 3.200000047683716,\n",
       " 3.0,\n",
       " 0.6000000238418579,\n",
       " 1.0,\n",
       " 0.6000000238418579,\n",
       " 0.800000011920929,\n",
       " 2.4000000953674316,\n",
       " 1.0,\n",
       " 0.20000000298023224,\n",
       " 0.6000000238418579,\n",
       " 3.5999999046325684,\n",
       " 0.20000000298023224,\n",
       " 0.20000000298023224,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.2000000476837158,\n",
       " 0.0,\n",
       " 0.4000000059604645,\n",
       " 0.4000000059604645,\n",
       " 3.0,\n",
       " 4.400000095367432,\n",
       " 3.200000047683716,\n",
       " 3.4000000953674316,\n",
       " 3.4000000953674316,\n",
       " 3.5999999046325684,\n",
       " 0.800000011920929,\n",
       " 0.800000011920929,\n",
       " 1.0,\n",
       " 1.600000023841858,\n",
       " 1.0,\n",
       " 3.200000047683716,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 0.6000000238418579,\n",
       " 0.0,\n",
       " 1.399999976158142,\n",
       " 2.0,\n",
       " 2.5999999046325684,\n",
       " 4.199999809265137,\n",
       " 2.799999952316284,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 2.5999999046325684,\n",
       " 2.5999999046325684,\n",
       " 0.0,\n",
       " 2.5999999046325684,\n",
       " 0.0,\n",
       " 1.600000023841858,\n",
       " 0.0,\n",
       " 0.6000000238418579,\n",
       " 1.7999999523162842,\n",
       " 3.799999952316284,\n",
       " 1.600000023841858,\n",
       " 3.200000047683716,\n",
       " 2.5999999046325684,\n",
       " 3.0,\n",
       " 1.399999976158142,\n",
       " 1.600000023841858,\n",
       " 1.600000023841858,\n",
       " 1.0,\n",
       " 1.7999999523162842,\n",
       " 1.7999999523162842,\n",
       " 1.399999976158142,\n",
       " 2.5999999046325684,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.399999976158142,\n",
       " 0.6000000238418579,\n",
       " 1.399999976158142,\n",
       " 0.4000000059604645,\n",
       " 1.7999999523162842,\n",
       " 4.0,\n",
       " 0.6000000238418579,\n",
       " 2.799999952316284,\n",
       " 2.5999999046325684,\n",
       " 2.5999999046325684,\n",
       " 0.6000000238418579,\n",
       " 4.400000095367432,\n",
       " 2.200000047683716,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.600000023841858,\n",
       " 1.7999999523162842,\n",
       " 3.799999952316284,\n",
       " 3.0,\n",
       " 1.399999976158142,\n",
       " 3.0,\n",
       " 0.4000000059604645,\n",
       " 3.5999999046325684,\n",
       " 3.4000000953674316,\n",
       " 2.799999952316284,\n",
       " 4.199999809265137,\n",
       " 4.199999809265137,\n",
       " 1.7999999523162842,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 1.600000023841858,\n",
       " 2.5999999046325684,\n",
       " 3.200000047683716,\n",
       " 0.4000000059604645,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.200000047683716,\n",
       " 1.5,\n",
       " 0.6000000238418579,\n",
       " 4.0,\n",
       " 1.7999999523162842,\n",
       " 0.6000000238418579,\n",
       " 1.600000023841858,\n",
       " 2.4000000953674316,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.600000023841858,\n",
       " 0.20000000298023224,\n",
       " 0.20000000298023224,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 3.200000047683716,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 2.4000000953674316,\n",
       " 0.0,\n",
       " 1.600000023841858,\n",
       " 3.799999952316284,\n",
       " 1.2000000476837158,\n",
       " 2.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 0.6000000238418579,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.4000000953674316,\n",
       " 2.5999999046325684,\n",
       " 0.4000000059604645,\n",
       " 2.799999952316284,\n",
       " 2.0,\n",
       " 1.600000023841858,\n",
       " 1.399999976158142,\n",
       " 1.2000000476837158,\n",
       " 2.200000047683716,\n",
       " 0.6000000238418579,\n",
       " 2.5999999046325684,\n",
       " 3.0,\n",
       " 2.200000047683716,\n",
       " 1.7999999523162842,\n",
       " 0.6000000238418579,\n",
       " 0.0,\n",
       " 1.600000023841858,\n",
       " 0.800000011920929,\n",
       " 0.20000000298023224,\n",
       " 1.0,\n",
       " 2.799999952316284,\n",
       " 0.6000000238418579,\n",
       " 2.799999952316284,\n",
       " 1.600000023841858,\n",
       " 1.399999976158142,\n",
       " 1.399999976158142,\n",
       " 3.0,\n",
       " 3.200000047683716,\n",
       " 2.799999952316284,\n",
       " 3.4000000953674316,\n",
       " 2.0,\n",
       " 2.799999952316284,\n",
       " 0.0,\n",
       " 0.20000000298023224,\n",
       " 0.800000011920929,\n",
       " 0.0,\n",
       " 4.199999809265137,\n",
       " 0.20000000298023224,\n",
       " 3.200000047683716,\n",
       " 0.0,\n",
       " 0.6000000238418579,\n",
       " 0.0,\n",
       " 4.800000190734863,\n",
       " 3.799999952316284,\n",
       " 1.7999999523162842,\n",
       " 0.4000000059604645,\n",
       " 2.5999999046325684,\n",
       " 1.600000023841858,\n",
       " 1.399999976158142,\n",
       " 2.0,\n",
       " 1.7999999523162842,\n",
       " 1.2000000476837158,\n",
       " 0.800000011920929,\n",
       " 2.200000047683716,\n",
       " 3.200000047683716,\n",
       " 1.399999976158142,\n",
       " 1.399999976158142,\n",
       " 0.0,\n",
       " 1.600000023841858,\n",
       " 0.800000011920929,\n",
       " 2.799999952316284,\n",
       " 1.7999999523162842,\n",
       " 0.6700000166893005,\n",
       " 2.5999999046325684,\n",
       " 0.4000000059604645,\n",
       " 2.4000000953674316,\n",
       " 2.799999952316284,\n",
       " 2.0,\n",
       " 3.0,\n",
       " 2.5999999046325684,\n",
       " 1.7999999523162842,\n",
       " 3.799999952316284,\n",
       " 3.0,\n",
       " 1.399999976158142,\n",
       " 1.600000023841858,\n",
       " 0.0,\n",
       " 0.6000000238418579,\n",
       " 0.0,\n",
       " 3.4000000953674316,\n",
       " 3.5999999046325684,\n",
       " 2.200000047683716,\n",
       " 3.0,\n",
       " 1.7999999523162842,\n",
       " 2.4000000953674316,\n",
       " 2.5999999046325684,\n",
       " 1.399999976158142,\n",
       " 1.600000023841858,\n",
       " 1.600000023841858,\n",
       " 1.399999976158142,\n",
       " 2.799999952316284,\n",
       " 3.799999952316284,\n",
       " 3.4000000953674316,\n",
       " 0.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 3.799999952316284,\n",
       " 0.20000000298023224,\n",
       " 0.6000000238418579,\n",
       " 1.7999999523162842,\n",
       " 1.7999999523162842,\n",
       " 1.2000000476837158,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.4000000059604645,\n",
       " 0.800000011920929,\n",
       " 3.0,\n",
       " 3.799999952316284,\n",
       " 3.200000047683716,\n",
       " 2.5999999046325684,\n",
       " 3.0,\n",
       " 2.5999999046325684,\n",
       " 1.7999999523162842,\n",
       " 2.5999999046325684,\n",
       " 0.800000011920929,\n",
       " 1.600000023841858,\n",
       " 0.6000000238418579,\n",
       " 2.5999999046325684,\n",
       " 1.2000000476837158,\n",
       " 0.0,\n",
       " 2.4000000953674316,\n",
       " 0.4000000059604645,\n",
       " 0.6000000238418579,\n",
       " 1.0,\n",
       " 2.5999999046325684,\n",
       " 4.0,\n",
       " 3.5999999046325684,\n",
       " 2.5999999046325684,\n",
       " 1.600000023841858,\n",
       " 4.0,\n",
       " 3.0,\n",
       " 0.6000000238418579,\n",
       " 0.0,\n",
       " 0.4000000059604645,\n",
       " 0.4000000059604645,\n",
       " 2.0,\n",
       " 0.6000000238418579,\n",
       " 0.0,\n",
       " 3.200000047683716,\n",
       " 2.799999952316284,\n",
       " 2.5999999046325684,\n",
       " 2.799999952316284,\n",
       " 0.20000000298023224,\n",
       " 3.200000047683716,\n",
       " 0.6000000238418579,\n",
       " 3.5999999046325684,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 2.200000047683716,\n",
       " 0.0,\n",
       " 0.4000000059604645,\n",
       " 0.0,\n",
       " 2.5999999046325684,\n",
       " 0.800000011920929,\n",
       " 0.4000000059604645,\n",
       " 3.0,\n",
       " 2.200000047683716,\n",
       " 0.6000000238418579,\n",
       " 3.4000000953674316,\n",
       " 2.200000047683716,\n",
       " 1.7999999523162842,\n",
       " 0.800000011920929,\n",
       " 0.0,\n",
       " 1.600000023841858,\n",
       " 2.799999952316284,\n",
       " 1.6699999570846558,\n",
       " 1.7999999523162842,\n",
       " 2.799999952316284,\n",
       " 0.0,\n",
       " 0.6000000238418579,\n",
       " 1.7999999523162842,\n",
       " 0.4000000059604645,\n",
       " 0.20000000298023224,\n",
       " 0.0,\n",
       " 1.399999976158142,\n",
       " 0.0,\n",
       " 0.6000000238418579,\n",
       " 0.800000011920929,\n",
       " 0.20000000298023224,\n",
       " 2.200000047683716,\n",
       " 1.7999999523162842,\n",
       " 0.20000000298023224,\n",
       " 4.0,\n",
       " 4.199999809265137,\n",
       " 4.400000095367432,\n",
       " 3.0,\n",
       " 2.5999999046325684,\n",
       " 0.6000000238418579,\n",
       " 3.200000047683716,\n",
       " 2.5999999046325684,\n",
       " 1.2000000476837158,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 2.5999999046325684,\n",
       " 1.2000000476837158,\n",
       " 2.799999952316284,\n",
       " 0.20000000298023224,\n",
       " 1.7999999523162842,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 3.0,\n",
       " 0.0,\n",
       " 2.4000000953674316,\n",
       " 0.4000000059604645,\n",
       " 2.5999999046325684,\n",
       " 0.0,\n",
       " 3.5999999046325684,\n",
       " 1.7999999523162842,\n",
       " 1.600000023841858,\n",
       " 2.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " 2.5999999046325684,\n",
       " 0.4000000059604645,\n",
       " 0.0,\n",
       " 0.20000000298023224,\n",
       " 1.7999999523162842,\n",
       " 1.600000023841858,\n",
       " 1.0,\n",
       " 0.6000000238418579,\n",
       " 1.0,\n",
       " 2.799999952316284,\n",
       " 2.5999999046325684,\n",
       " 3.4000000953674316,\n",
       " 1.600000023841858,\n",
       " 4.0,\n",
       " 1.7999999523162842,\n",
       " 0.20000000298023224,\n",
       " 0.0,\n",
       " 1.399999976158142,\n",
       " 0.0,\n",
       " 1.2000000476837158,\n",
       " 3.5999999046325684,\n",
       " 3.0,\n",
       " 1.2000000476837158,\n",
       " 1.7999999523162842,\n",
       " 0.800000011920929,\n",
       " 1.2000000476837158,\n",
       " 0.0,\n",
       " 3.200000047683716,\n",
       " 0.20000000298023224,\n",
       " ...]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_b['validation']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4899a6424d9f4d99b195c77d6a81ee26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1366a5bb7580422790dee2c73122a806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f295394a3d894f2e9cae0a6a22390b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb08bd7fad0a40b490d2f5dcf37cc489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb77e3c5c4a44c8e933b36bde5c0faab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperbolic Model Performance:\n",
      "STS-B: {'pearson_correlation': np.float64(0.7610805140114083)}\n",
      "\n",
      "Euclidean Model Performance:\n",
      "STS-B: {'pearson_correlation': np.float64(0.876909302337823)}\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Convert dataset to proper format\n",
    "def prepare_sentence_transformer_dataset(dataset):\n",
    "    return [{\"sentence1\": s1, \"sentence2\": s2, \"labels\": label} \n",
    "            for s1, s2, label in zip(dataset[\"sentence1\"], dataset[\"sentence2\"], dataset[\"label\"])]\n",
    "\n",
    "# Prepare datasets\n",
    "sts_b_data = prepare_sentence_transformer_dataset(sts_b[\"validation\"])\n",
    "\n",
    "# Load SentenceTransformer models\n",
    "hit_model = SentenceTransformer(\"Hierarchy-Transformers/HiT-MiniLM-L12-WordNetNoun\")\n",
    "elm_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "\n",
    "# Evaluate models\n",
    "print(\"Hyperbolic Model Performance:\")\n",
    "print(\"STS-B:\", evaluate_model(hit_model, sts_b_data, is_regression=True))\n",
    "\n",
    "print(\"\\nEuclidean Model Performance:\")\n",
    "print(\"STS-B:\", evaluate_model(elm_model, sts_b_data, is_regression=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hitmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
